{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f385eda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9726cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sandy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42d28b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize & Calculate frequency\n",
    "stopwords = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "\n",
    "document_frequencies = {} #紀錄單字出現次數\n",
    "filtered_tokens_list = {} #紀錄所有token\n",
    "num_files = 1095 \n",
    "\n",
    "for i in range(1, num_files + 1):\n",
    "    filename = os.path.join('IRTM', f\"{i}.txt\")\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        text = content\n",
    "        \n",
    "        # Remove punctuation mark and lowercasing\n",
    "        punctuation = ',.!?;:\"`()_' \n",
    "        punctuation += \"'\" # except -\n",
    "        for char in punctuation:\n",
    "            text = text.replace(char, '')\n",
    "        tokens = text.lower().split()\n",
    "        \n",
    "        # Stemming\n",
    "        stemmer = PorterStemmer()\n",
    "        stemmed_words = [stemmer.stem(word) for word in tokens]\n",
    "        \n",
    "        # Remove stopwords\n",
    "        filtered_tokens = [word for word in tokens if word not in stopwords]\n",
    "        filtered_tokens_list[i] = filtered_tokens\n",
    "        \n",
    "        for term in filtered_tokens:\n",
    "            if term in document_frequencies:\n",
    "                document_frequencies[term] += 1\n",
    "            else:\n",
    "                document_frequencies[term] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ff7fb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "with open('dictionary.txt', 'w') as f:\n",
    "    for term in sorted(document_frequencies.keys()):\n",
    "        f.write(f\"{i} {term} {document_frequencies[term]}\\n\")\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cc53552",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_list = []\n",
    "df = defaultdict(int)\n",
    "for i in range(1, num_files + 1):\n",
    "    term_frequencies = {}\n",
    "    for term in filtered_tokens_list[i]:\n",
    "        if term in term_frequencies:\n",
    "                term_frequencies[term] += 1\n",
    "        else:\n",
    "            term_frequencies[term] = 1\n",
    "                \n",
    "    sum_term = sum(term_frequencies.values())\n",
    "    tf = {}\n",
    "    \n",
    "    for term, count in term_frequencies.items():\n",
    "        tf[term] = count / sum_term  # 計算 TF\n",
    "        df[term] += 1\n",
    "\n",
    "    tf_list.append(tf)\n",
    "# 計算 IDF    \n",
    "idf = {}\n",
    "for term, doc_count in df.items():\n",
    "    idf[term] = math.log(num_files / doc_count)\n",
    "    \n",
    "# 計算 TF-IDF\n",
    "tf_idf_list = []\n",
    "for tf in tf_list:\n",
    "    tf_idf = {}\n",
    "    for term, tf_value in tf.items():\n",
    "        tf_idf[term] = tf_value * idf[term]  \n",
    "    tf_idf_list.append(tf_idf)\n",
    "  \n",
    " # 將 TF-IDF 轉換為單位向量\n",
    "unit_vectors = []\n",
    "for tf_idf in tf_idf_list:\n",
    "    magnitude = math.sqrt(sum(value ** 2 for value in tf_idf.values()))\n",
    "    unit_vector = {term: value / magnitude for term, value in tf_idf.items()} if magnitude > 0 else {}\n",
    "    unit_vectors.append(unit_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9714e2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = sorted(document_frequencies.keys())  # 按詞的字母順序排序\n",
    "term_to_index = {term: index for index, term in enumerate(terms)} #單字的編號順序\n",
    "\n",
    "for i in range(1, num_files + 1):\n",
    "    filename = os.path.join('output', f\"{i}.txt\")\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        current_tf_idf = tf_idf_list[i - 1]  \n",
    "        file.write(f\"{len(current_tf_idf)}\\n\") # The number of terms document has \n",
    "\n",
    "        for term in terms:\n",
    "            if term in current_tf_idf:\n",
    "                index = term_to_index[term]\n",
    "                value = current_tf_idf[term]\n",
    "                file.write(f\"{index}    {value:.6f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf6ec829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取檔案\n",
    "def load_vector(doc_name):\n",
    "    vector = {}\n",
    "    with open(doc_name, 'r', encoding='utf-8') as file:\n",
    "        next(file)  # The number of terms document has \n",
    "        for line in file:\n",
    "            index, value = line.split()\n",
    "            vector[int(index)] = float(value)\n",
    "    return vector\n",
    "\n",
    "def cosine(docx, docy):\n",
    "    vector_x = load_vector(docx)\n",
    "    vector_y = load_vector(docy)\n",
    "    \n",
    "    # 所有出現的單字集\n",
    "    all_indices = set(vector_x.keys()).union(set(vector_y.keys()))\n",
    "    \n",
    "    # 統一長度將沒出現的單字填入0\n",
    "    tf_idf_x = np.array([vector_x.get(i, 0) for i in range(len(all_indices))])\n",
    "    tf_idf_y = np.array([vector_y.get(i, 0) for i in range(len(all_indices))])\n",
    "    \n",
    "    # Calculate the cosine similarity\n",
    "    dot = np.dot(tf_idf_x, tf_idf_y)\n",
    "    len_x = np.linalg.norm(tf_idf_x)\n",
    "    len_y = np.linalg.norm(tf_idf_y)\n",
    "    \n",
    "    if len_x == 0 or len_y == 0:\n",
    "        return 0.0\n",
    "\n",
    "    cosine_similarity = dot / (len_x * len_y)\n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cea898b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.000000\n"
     ]
    }
   ],
   "source": [
    "x=1\n",
    "y=2\n",
    "similarity = cosine(f\"output/{x}.txt\", f\"output/{y}.txt\")\n",
    "print(f\"Cosine Similarity: {similarity:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ba3747",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
